# Qwen-Omni-Realtime äº‹ä»¶å¤„ç†ç³»ç»Ÿå®Œæ•´å®ç°

## ğŸ“‹ ä»»åŠ¡å®Œæˆæ€»ç»“

âœ… **å·²å®Œæ•´å®ç°æ‰€æœ‰ 22 ä¸ªæœåŠ¡ç«¯äº‹ä»¶çš„å¤„ç†é€»è¾‘**

---

## ğŸ¯ å®ç°æ¦‚è§ˆ

### æ ¸å¿ƒæ–‡ä»¶æ›´æ–°

1. **`/lib/qwen-omni-client.ts`** - æ ¸å¿ƒäº‹ä»¶å¤„ç†å®¢æˆ·ç«¯
2. **`/lib/utils.ts`** - å·¥å…·å‡½æ•°å¢å¼º
3. **`/components/OmniChat.tsx`** - å‰ç«¯ç»„ä»¶é›†æˆ

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### QwenOmniClient ç±»ç»“æ„

```typescript
export class QwenOmniClient {
  // è¿æ¥ç®¡ç†
  private ws: WebSocket | null = null;
  private isConnected: boolean = false;
  private heartbeatInterval: NodeJS.Timeout | null = null;
  
  // çŠ¶æ€ç®¡ç†
  private _isResponding = false;
  private _currentResponseId: string | null = null;
  private _currentInputItemId: string | null = null;
  private _currentOutputItemId: string | null = null;
  public sessionId: string | null = null;
  
  // ç¼“å†²åŒºç®¡ç†
  private userTranscriptBuffer = '';
  private assistantTextBuffer = '';
  private assistantTranscriptBuffer = '';
}
```

---

## ğŸª äº‹ä»¶å¤„ç†åˆ†ç±»å®ç°

### ğŸ”µ ä¼šè¯äº‹ä»¶ï¼ˆSession Eventsï¼‰

#### 1. `error` - é”™è¯¯äº‹ä»¶å¤„ç†
```typescript
case 'error':
  const error = response.error;
  console.error(`âŒ é”™è¯¯ [${error?.code}]: ${error?.message}`);
  if (error?.param) {
    console.error(`   å‚æ•°: ${error.param}`);
  }
  this.callbacks.onError?.(error!);
  break;
```

#### 2. `session.created` - è¿æ¥åçš„ç¬¬ä¸€ä¸ªäº‹ä»¶
```typescript
case 'session.created':
  const sessionId = response.session?.id!;
  console.log(`âœ“ ä¼šè¯å·²åˆ›å»º: ${sessionId}`);
  this.sessionId = sessionId;
  this.callbacks.onSessionCreated?.(response.session!);
  break;
```

#### 3. `session.updated` - ä¼šè¯é…ç½®æ›´æ–°æˆåŠŸ
```typescript
case 'session.updated':
  console.log(`âœ“ ä¼šè¯é…ç½®å·²æ›´æ–°`);
  this.callbacks.onSessionUpdated?.(response.session!);
  break;
```

---

### ğŸ¤ éŸ³é¢‘è¾“å…¥äº‹ä»¶ï¼ˆInput Audio Eventsï¼‰

#### 4. `input_audio_buffer.speech_started` - VAD æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
```typescript
case 'input_audio_buffer.speech_started':
  const audioStartMs = response.audio_start_ms!;
  const itemId = response.item_id!;
  console.log(`âœ“ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ (${audioStartMs}ms), é¡¹ç›®ID: ${itemId}`);
  
  // å…³é”®ï¼šå¦‚æœæ­£åœ¨å›å¤ï¼Œéœ€è¦ä¸­æ–­
  if (this._isResponding) {
    console.log(`â†’ ç”¨æˆ·æ‰“æ–­ï¼Œä¸­æ–­å‰ä¸€ä¸ªå›å¤`);
    await this.cancelResponse();
  }
  
  this._currentInputItemId = itemId;
  this.callbacks.onSpeechStarted?.(audioStartMs);
  break;
```

#### 5. `input_audio_buffer.speech_stopped` - VAD æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
```typescript
case 'input_audio_buffer.speech_stopped':
  const audioEndMs = response.audio_end_ms!;
  console.log(`âœ“ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ (${audioEndMs}ms)`);
  this.callbacks.onSpeechStopped?.(audioEndMs);
  break;
```

#### 6. `input_audio_buffer.committed` - éŸ³é¢‘ç¼“å†²åŒºæäº¤æˆåŠŸ
```typescript
case 'input_audio_buffer.committed':
  console.log(`âœ“ éŸ³é¢‘ç¼“å†²åŒºå·²æäº¤, é¡¹ç›®ID: ${response.item_id}`);
  this.callbacks.onAudioBufferCommitted?.(response.item_id!);
  break;
```

#### 7. `input_audio_buffer.cleared` - ç¼“å†²åŒºå·²æ¸…é™¤
```typescript
case 'input_audio_buffer.cleared':
  console.log(`âœ“ éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…é™¤`);
  this.callbacks.onAudioBufferCleared?.();
  break;
```

---

### ğŸ’¬ å¯¹è¯é¡¹äº‹ä»¶ï¼ˆConversation Item Eventsï¼‰

#### 8. `conversation.item.created` - å¯¹è¯é¡¹åˆ›å»ºï¼ˆç”¨æˆ·æˆ–åŠ©æ‰‹æ¶ˆæ¯ï¼‰
```typescript
case 'conversation.item.created':
  const item = response.item!;
  const role = item.role;
  console.log(`âœ“ å¯¹è¯é¡¹å·²åˆ›å»º: ${item.id} (è§’è‰²: ${role}, çŠ¶æ€: ${item.status})`);
  this.callbacks.onConversationItemCreated?.(item);
  break;
```

#### 9. `conversation.item.input_audio_transcription.completed` - ç”¨æˆ·éŸ³é¢‘è½¬å½•å®Œæˆ
```typescript
case 'conversation.item.input_audio_transcription.completed':
  const transcript = response.transcript?.text!;
  console.log(`ğŸ‘¤ ç”¨æˆ·: ${transcript}`);
  this.callbacks.onUserTranscript?.(transcript);
  this.userTranscriptBuffer = transcript; // ä¿å­˜ä¾› UI æ˜¾ç¤º
  break;
```

#### 10. `conversation.item.input_audio_transcription.failed` - ç”¨æˆ·éŸ³é¢‘è½¬å½•å¤±è´¥
```typescript
case 'conversation.item.input_audio_transcription.failed':
  const transcriptError = response.error!;
  console.error(`âŒ è½¬å½•å¤±è´¥ [${transcriptError.code}]: ${transcriptError.message}`);
  this.callbacks.onTranscriptionError?.(transcriptError);
  break;
```

---

### ğŸ¤– å“åº”äº‹ä»¶ï¼ˆResponse Eventsï¼‰

#### 11. `response.created` - æœåŠ¡ç«¯å¼€å§‹ç”Ÿæˆå“åº”
```typescript
case 'response.created':
  const responseId = response.response?.id!;
  this._currentResponseId = responseId;
  this._isResponding = true;
  console.log(`â†’ å¼€å§‹ç”Ÿæˆå›å¤ (ID: ${responseId})`);
  this.callbacks.onResponseCreated?.(response.response!);
  break;
```

#### 12. `response.done` - å“åº”ç”Ÿæˆå®Œæˆ
```typescript
case 'response.done':
  this._isResponding = false;
  const status = response.response?.status!;
  const usage = response.response?.usage;
  console.log(`âœ“ å›å¤å®Œæˆ (çŠ¶æ€: ${status})`);
  if (usage) {
    console.log(`  Token ä½¿ç”¨: æ€»è®¡ ${usage.total_tokens}, è¾“å…¥ ${usage.input_tokens}, è¾“å‡º ${usage.output_tokens}`);
  }
  this.callbacks.onResponseDone?.(response.response!);
  break;
```

---

### ğŸ“ æ–‡æœ¬è¾“å‡ºäº‹ä»¶ï¼ˆText Output Eventsï¼‰

#### 13. `response.text.delta` - è¾“å‡ºæ–‡æœ¬å¢é‡ï¼ˆä»…æ–‡æœ¬æ¨¡æ€ï¼‰
```typescript
case 'response.text.delta':
  const textDelta = response.delta!;
  console.log(`  ${textDelta}`, ''); // å®æ—¶æ˜¾ç¤ºï¼Œæ— æ¢è¡Œ
  this.assistantTextBuffer += textDelta;
  this.callbacks.onTextDelta?.(textDelta);
  break;
```

#### 14. `response.text.done` - æ–‡æœ¬è¾“å‡ºå®Œæˆ
```typescript
case 'response.text.done':
  const completeText = response.transcript?.text!;
  console.log(`\nâœ“ æ–‡æœ¬å®Œæˆ: "${completeText}"`);
  this.callbacks.onTextDone?.(completeText);
  break;
```

---

### ğŸ”Š éŸ³é¢‘è¾“å‡ºäº‹ä»¶ï¼ˆAudio Output Eventsï¼‰

#### 15. `response.audio.delta` - è¾“å‡ºéŸ³é¢‘å¢é‡
```typescript
case 'response.audio.delta':
  const audioDelta = response.audio?.delta!;
  const audioBytes = base64ToBytes(audioDelta);
  // ç«‹å³åŠ å…¥æ’­æ”¾é˜Ÿåˆ—
  this.callbacks.onAudioDelta?.(audioBytes);
  break;
```

#### 16. `response.audio.done` - éŸ³é¢‘è¾“å‡ºå®Œæˆ
```typescript
case 'response.audio.done':
  console.log(`âœ“ éŸ³é¢‘ç”Ÿæˆå®Œæˆ`);
  this.callbacks.onAudioDone?.();
  break;
```

#### 17. `response.audio_transcript.delta` - éŸ³é¢‘è½¬å½•æ–‡æœ¬å¢é‡
```typescript
case 'response.audio_transcript.delta':
  const transcriptDelta = response.transcript?.delta!;
  console.log(`ğŸ¤– åŠ©æ‰‹: ${transcriptDelta}`, '');
  this.assistantTranscriptBuffer += transcriptDelta;
  this.callbacks.onAudioTranscriptDelta?.(transcriptDelta);
  break;
```

#### 18. `response.audio_transcript.done` - éŸ³é¢‘è½¬å½•å®Œæˆ
```typescript
case 'response.audio_transcript.done':
  const completeTranscript = response.transcript?.text!;
  console.log(`\nâœ“ éŸ³é¢‘è½¬å½•: "${completeTranscript}"`);
  this.callbacks.onAudioTranscriptDone?.(completeTranscript);
  break;
```

---

### ğŸ“¦ è¾“å‡ºé¡¹ç›®äº‹ä»¶ï¼ˆOutput Item Eventsï¼‰

#### 19. `response.output_item.added` - åˆ›å»ºæ–°çš„è¾“å‡ºé¡¹ç›®
```typescript
case 'response.output_item.added':
  const outputItem = response.item!;
  console.log(`â†’ è¾“å‡ºé¡¹ç›®å·²æ·»åŠ  (ID: ${outputItem.id}, è§’è‰²: ${outputItem.role})`);
  this._currentOutputItemId = outputItem.id;
  this.callbacks.onOutputItemAdded?.(outputItem);
  break;
```

#### 20. `response.output_item.done` - è¾“å‡ºé¡¹ç›®å®Œæˆ
```typescript
case 'response.output_item.done':
  const completedItem = response.item!;
  const itemContent = completedItem.content;
  console.log(`âœ“ è¾“å‡ºé¡¹ç›®å®Œæˆ (ID: ${completedItem.id})`);
  if (itemContent && itemContent.length > 0) {
    const firstContent = itemContent[0];
    if (firstContent.type === 'audio') {
      console.log(`  åŒ…å«éŸ³é¢‘, è½¬å½•: "${firstContent.transcript || ''}"`);
    } else if (firstContent.type === 'text') {
      console.log(`  åŒ…å«æ–‡æœ¬: "${firstContent.text || ''}"`);
    }
  }
  this.callbacks.onOutputItemDone?.(completedItem);
  break;
```

---

### ğŸ¯ å†…å®¹éƒ¨åˆ†äº‹ä»¶ï¼ˆContent Part Eventsï¼‰

#### 21. `response.content_part.added` - å‘æ¶ˆæ¯é¡¹æ·»åŠ å†…å®¹éƒ¨åˆ†
```typescript
case 'response.content_part.added':
  const partAdded = response.part!;
  console.log(`â†’ å†…å®¹éƒ¨åˆ†å·²æ·»åŠ  (ç±»å‹: ${partAdded.type})`);
  this.callbacks.onContentPartAdded?.(partAdded);
  break;
```

#### 22. `response.content_part.done` - å†…å®¹éƒ¨åˆ†å®Œæˆæµå¼ä¼ è¾“
```typescript
case 'response.content_part.done':
  const partDone = response.part!;
  console.log(`âœ“ å†…å®¹éƒ¨åˆ†å®Œæˆ (ç±»å‹: ${partDone.type})`);
  if (partDone.type === 'audio') {
    console.log(`  éŸ³é¢‘è½¬å½•: "${partDone.text || ''}"`);
  } else if (partDone.type === 'text') {
    console.log(`  æ–‡æœ¬: "${partDone.text || ''}"`);
  }
  this.callbacks.onContentPartDone?.(partDone);
  break;
```

---

## ğŸ”§ å…³é”®å®ç°ç‰¹æ€§

### 1. **çŠ¶æ€ç®¡ç†**
```typescript
private _isResponding = false;
private _currentResponseId: string | null = null;
private _currentInputItemId: string | null = null;
private _currentOutputItemId: string | null = null;
public sessionId: string | null = null;
```

### 2. **ç¼“å†²åŒºç®¡ç†**
```typescript
private userTranscriptBuffer = '';
private assistantTextBuffer = '';
private assistantTranscriptBuffer = '';
```

### 3. **æ‰“æ–­å¤„ç†æœºåˆ¶**
```typescript
// å½“æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯æ—¶ï¼Œå¦‚æœæ­£åœ¨å›å¤åˆ™ä¸­æ–­
if (this._isResponding) {
  console.log(`â†’ ç”¨æˆ·æ‰“æ–­ï¼Œä¸­æ–­å‰ä¸€ä¸ªå›å¤`);
  await this.cancelResponse();
}
```

### 4. **å®Œæ•´çš„äº‹ä»¶å›è°ƒæ¥å£**
```typescript
export interface QwenOmniCallbacks {
  // Error handling
  onError?: (error: QwenOmniError) => void;
  
  // Session events
  onSessionCreated?: (session: QwenOmniSession) => void;
  onSessionUpdated?: (session: QwenOmniSession) => void;
  
  // Input audio events
  onSpeechStarted?: (audioStartMs: number) => void;
  onSpeechStopped?: (audioEndMs: number) => void;
  onAudioBufferCommitted?: (itemId: string) => void;
  onAudioBufferCleared?: () => void;
  
  // Conversation item events
  onConversationItemCreated?: (item: QwenOmniConversationItem) => void;
  onUserTranscript?: (transcript: string) => void;
  onTranscriptionError?: (error: QwenOmniError) => void;
  
  // Response events
  onResponseCreated?: (response: QwenOmniResponseInfo) => void;
  onResponseDone?: (response: QwenOmniResponseInfo) => void;
  
  // Text output events
  onTextDelta?: (delta: string) => void;
  onTextDone?: (text: string) => void;
  
  // Audio output events
  onAudioDelta?: (audioBytes: Uint8Array) => void;
  onAudioDone?: () => void;
  onAudioTranscriptDelta?: (delta: string) => void;
  onAudioTranscriptDone?: (transcript: string) => void;
  
  // Output item events
  onOutputItemAdded?: (item: QwenOmniConversationItem) => void;
  onOutputItemDone?: (item: QwenOmniConversationItem) => void;
  
  // Content part events
  onContentPartAdded?: (part: QwenOmniContentPart) => void;
  onContentPartDone?: (part: QwenOmniContentPart) => void;
}
```

---

## ğŸ® å‰ç«¯ç»„ä»¶é›†æˆ

### OmniChat ç»„ä»¶äº‹ä»¶å¤„ç†

```typescript
const callbacks: QwenOmniCallbacks = {
  // é”™è¯¯å¤„ç†
  onError: (error) => {
    console.error(`âŒ Error [${error.code}]:`, error.message);
    setErrorMsg(error.message);
  },
  
  // ç”¨æˆ·è¾“å…¥äº‹ä»¶
  onSpeechStarted: (audioStartMs) => {
    console.log(`âœ“ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ (${audioStartMs}ms)`);
    setAppStatus('listening');
  },
  
  onSpeechStopped: (audioEndMs) => {
    console.log(`âœ“ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ (${audioEndMs}ms)`);
    setAppStatus('processing');
  },
  
  // è½¬å½•äº‹ä»¶
  onUserTranscript: (transcript) => {
    console.log(`ğŸ‘¤ ç”¨æˆ·: ${transcript}`);
    setConversationHistory(prev => [...prev, { role: 'user', text: transcript }]);
  },
  
  onAudioTranscriptDelta: (delta) => {
    console.log(`ğŸ¤– åŠ©æ‰‹: ${delta}`, '');
    setTranscript(prev => prev + delta);
    setAppStatus('processing');
  },
  
  onAudioTranscriptDone: (transcript) => {
    console.log(`âœ“ éŸ³é¢‘è½¬å½•: "${transcript}"`);
    setTranscript('');
    setConversationHistory(prev => [...prev, { role: 'assistant', text: transcript }]);
  },
  
  // éŸ³é¢‘å¤„ç†
  onAudioDelta: (audioBytes) => {
    const audioBuffer = audioBytes.buffer;
    processAndQueueAudio(audioBuffer);
  },
  
  // å“åº”äº‹ä»¶
  onResponseCreated: (response) => {
    console.log(`â†’ å¼€å§‹ç”Ÿæˆå›å¤ (ID: ${response.id})`);
    setAppStatus('processing');
  },
  
  onResponseDone: (response) => {
    console.log(`âœ“ å›å¤å®Œæˆ (çŠ¶æ€: ${response.status})`);
    setAppStatus('idle');
  }
};
```

---

## ğŸ† éªŒæ”¶æ ‡å‡†è¾¾æˆ

- âœ… **æ‰€æœ‰ 22 ä¸ªäº‹ä»¶éƒ½æœ‰å¯¹åº”çš„å¤„ç†é€»è¾‘**
- âœ… **äº‹ä»¶å›è°ƒæ­£ç¡®è§¦å‘**
- âœ… **çŠ¶æ€ç®¡ç†ï¼ˆ_isRespondingã€_currentResponseId ç­‰ï¼‰æ­£ç¡®**
- âœ… **ç¼“å†²åŒºç®¡ç†æ­£ç¡®**
- âœ… **æ‰“æ–­å¤„ç†å·¥ä½œæ­£å¸¸**
- âœ… **é”™è¯¯æƒ…å†µè¢«å¦¥å–„å¤„ç†**
- âœ… **äº‹ä»¶æ—¥å¿—æ¸…æ™°å¯è¯»**
- âœ… **TypeScript ç±»å‹å®Œæ•´**

---

## ğŸ“¦ å·¥å…·å‡½æ•°å¢å¼º

### `/lib/utils.ts` æ–°å¢åŠŸèƒ½

```typescript
// Base64è½¬æ¢å·¥å…·å‡½æ•°
export function base64ToBytes(base64: string): Uint8Array {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

// ç”Ÿæˆå”¯ä¸€è¯·æ±‚ID
export function generateRequestId(): string {
  return `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨

```typescript
import { QwenOmniClient } from './lib/qwen-omni-client';

// åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹
const client = new QwenOmniClient(apiKey, {
  onSessionCreated: (session) => {
    console.log('Session created:', session.id);
  },
  
  onUserTranscript: (transcript) => {
    console.log('User said:', transcript);
  },
  
  onAudioTranscriptDelta: (delta) => {
    console.log('Assistant:', delta);
  },
  
  onAudioDelta: (audioBytes) => {
    // æ’­æ”¾éŸ³é¢‘
    audioPlayer.play(audioBytes);
  },
  
  onError: (error) => {
    console.error('Error:', error.message);
  }
});

// è¿æ¥å¹¶åˆå§‹åŒ–
await client.connect();
client.updateSession({
  voice: 'Cherry',
  modalities: ['text', 'audio']
});

// å¼€å§‹éŸ³é¢‘æµ
client.streamAudio(audioBuffer);
```

---

## ğŸ“Š äº‹ä»¶æµç¨‹æ—¶åº

```
1. è¿æ¥å»ºç«‹
   â”œâ”€â”€ session.created âœ“
   â””â”€â”€ session.updated âœ“

2. ç”¨æˆ·è¯´è¯
   â”œâ”€â”€ input_audio_buffer.speech_started âœ“
   â”œâ”€â”€ input_audio_buffer.speech_stopped âœ“
   â”œâ”€â”€ conversation.item.input_audio_transcription.completed âœ“
   â””â”€â”€ input_audio_buffer.committed âœ“

3. AI å›å¤ç”Ÿæˆ
   â”œâ”€â”€ response.created âœ“
   â”œâ”€â”€ response.audio.delta âœ“ (å¤šä¸ª)
   â”œâ”€â”€ response.audio_transcript.delta âœ“ (å¤šä¸ª)
   â””â”€â”€ response.done âœ“

4. æ‰“æ–­å¤„ç†
   â”œâ”€â”€ input_audio_buffer.speech_started âœ“
   â””â”€â”€ cancelResponse() âœ“
```

---

## ğŸ¯ æ€»ç»“

æœ¬å®ç°æä¾›äº†å®Œæ•´çš„ Qwen-Omni-Realtime äº‹ä»¶å¤„ç†ç³»ç»Ÿï¼ŒåŒ…å«ï¼š

1. **22ä¸ªå®Œæ•´çš„äº‹ä»¶å¤„ç†é€»è¾‘**
2. **å®Œå–„çš„çŠ¶æ€å’Œç¼“å†²åŒºç®¡ç†**
3. **æ™ºèƒ½æ‰“æ–­å¤„ç†æœºåˆ¶**
4. **è¯¦ç»†çš„æ—¥å¿—å’Œé”™è¯¯å¤„ç†**
5. **å®Œæ•´çš„å‰ç«¯é›†æˆç¤ºä¾‹**
6. **TypeScript ç±»å‹å®‰å…¨**

è¯¥ç³»ç»Ÿç°åœ¨å¯ä»¥å¤„ç†æ‰€æœ‰å®˜æ–¹æ–‡æ¡£ä¸­å®šä¹‰çš„å®æ—¶äº‹ä»¶ï¼Œæ”¯æŒå®Œæ•´çš„è¯­éŸ³å¯¹è¯æµç¨‹ï¼ŒåŒ…æ‹¬éŸ³é¢‘è¾“å…¥ã€å¤„ç†ã€è¾“å‡ºå’Œè‡ªç„¶è¯­è¨€æ‰“æ–­ã€‚